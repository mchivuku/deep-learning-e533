{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework4_VAE.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mchivuku/deep-learning-e533/blob/master/Homework4_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "zNpjmQcod8U5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Variational Auto-Encoder"
      ]
    },
    {
      "metadata": {
        "id": "BLNEvG3Gd-Ai",
        "colab_type": "code",
        "outputId": "b3efa067-7e3e-46d9-fec3-8fbbd6188112",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "%cd /content/drive/My\\ Drive/Masters-DS/Deep\\ Learning\\ -\\ E533/\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Masters-DS/Deep Learning - E533\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "A_-jI3vvd-_V",
        "colab_type": "code",
        "outputId": "c2ce464d-2b59-4cd0-c1f9-fd29e1271442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%cd Homework4"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Masters-DS/Deep Learning - E533/Homework4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iw9lmt7EX1pK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install tqdm six\n",
        "\n",
        "\n",
        "!pip install bokeh\n",
        "!pip install tensorboard\n",
        "!pip install livelossplot\n",
        "\n",
        "!pip install tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-p_388EkXcEW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "metadata": {
        "id": "tDbVU6PfeKib",
        "colab_type": "code",
        "outputId": "f958c870-8ea9-4fc1-8a5d-e9719634d25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "import torchvision\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "from torch.optim import lr_scheduler\n",
        "from torch import optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.utils import make_grid\n",
        "import time\n",
        "from torchvision import datasets,transforms\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import os\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "## Plotting library\n",
        "\n",
        "from bokeh.plotting import figure\n",
        "from bokeh.io import show\n",
        "from bokeh.models import LinearAxis, Range1d\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "print(torch.cuda.is_available())\n",
        "\n",
        "is_cuda = torch.cuda.is_available()\n",
        "device = torch.device ( \"cuda:0\" if torch.cuda.is_available () else \"cpu\" )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch 1.0.1.post2 CUDA 10.0.130\n",
            "Device: cuda:0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6Vjsb7F1ZGG3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "id": "41TUEJmmXh0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Show image\n",
        "def imshow(img,title=None):\n",
        "  \"\"\"Imshow for Tensor.\"\"\"\n",
        "  img = img.numpy().transpose((1,2,0))\n",
        "  mean = np.array([0.485, 0.456, 0.406])\n",
        "  std = np.array([0.229, 0.224, 0.225])\n",
        "  img = std * img + mean # normalize\n",
        "  img = np.clip(img, 0, 1) # clip image\n",
        "  plt.figure(figsize=(16,4))\n",
        "  plt.axis('off')\n",
        "  plt.imshow(img)\n",
        "  \n",
        "  if title is not None:\n",
        "    plt.title(title)         \n",
        "  \n",
        "def plot_grid(inputs):\n",
        "  # Make a grid from batch \n",
        "  out = torchvision.utils.make_grid(inputs,10,10)\n",
        "  imshow(out, title=\"\")\n",
        "  \n",
        "  \n",
        "  \n",
        "  \n",
        "def plot_loss(y, title):\n",
        "  plt.figure()\n",
        "  plt.plot(y)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  \n",
        "def plot_accuracy(y, title):\n",
        "  plt.figure()\n",
        "  plt.plot(y)\n",
        "  plt.title(title)\n",
        "  plt.xlabel('epochs')\n",
        "  plt.ylabel('accuracy')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i8ugsQ7xZNny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## TensorBoard - Utilities"
      ]
    },
    {
      "metadata": {
        "id": "VHrmbMHZZICd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import scipy.misc \n",
        "from PIL import Image \n",
        "try:\n",
        "    from StringIO import StringIO  # Python 2.7\n",
        "except ImportError:\n",
        "    from io import BytesIO         # Python 3.x\n",
        "\n",
        "## Import tensor flow library\n",
        "class TensorBoardLogger(object):\n",
        "  \n",
        "  \"\"\"\n",
        "  Initialize the summary writer\n",
        "  \"\"\"\n",
        "  def __init__(self, log_dir):\n",
        "    \"create summary writer\"\n",
        "    self.writer = tf.summary.FileWriter(log_dir)\n",
        "  \n",
        "  \"\"\"\n",
        "  Add scalar\n",
        "  \"\"\"\n",
        "  def scalar_summary(self, tag, value, step):\n",
        "    summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
        "    self.writer.add_summary(summary,step)\n",
        "    \n",
        "  \"\"\"\n",
        "  Add images\n",
        "  \"\"\"\n",
        "  def image_summary(self, tag, images, step):\n",
        "    \"\"\"Log a list of images.\"\"\"\n",
        "\n",
        "    img_summaries = []\n",
        "    for i, img in enumerate(images):\n",
        "        s = BytesIO()\n",
        "        \n",
        "        new_p = Image.fromarray(img)\n",
        "        if new_p.mode != 'L':\n",
        "          new_p = new_p.convert('L')\n",
        "    \n",
        "        new_p.save(s, format=\"png\")\n",
        "\n",
        "        # Create an Image object\n",
        "        img_sum = tf.Summary.Image(encoded_image_string=s.getvalue(),\n",
        "                                   height=img.shape[0],\n",
        "                                   width=img.shape[1])\n",
        "        # Create a Summary value\n",
        "        img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
        "\n",
        "    # Create and write Summary\n",
        "    summary = tf.Summary(value=img_summaries)\n",
        "    self.writer.add_summary(summary, step)\n",
        "        \n",
        "  def histo_summary(self, tag, values, step, bins=1000):\n",
        "      \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
        "\n",
        "      # Create a histogram using numpy\n",
        "      counts, bin_edges = np.histogram(values, bins=bins)\n",
        "\n",
        "      # Fill the fields of the histogram proto\n",
        "      hist = tf.HistogramProto()\n",
        "      hist.min = float(np.min(values))\n",
        "      hist.max = float(np.max(values))\n",
        "      hist.num = int(np.prod(values.shape))\n",
        "      hist.sum = float(np.sum(values))\n",
        "      hist.sum_squares = float(np.sum(values**2))\n",
        "\n",
        "      # Drop the start of the first bin\n",
        "      bin_edges = bin_edges[1:]\n",
        "\n",
        "      # Add bin edges and counts\n",
        "      for edge in bin_edges:\n",
        "          hist.bucket_limit.append(edge)\n",
        "      for c in counts:\n",
        "          hist.bucket.append(c)\n",
        "\n",
        "      # Create and write Summary\n",
        "      summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
        "      self.writer.add_summary(summary, step)\n",
        "      self.writer.flush()\n",
        "      \n",
        "      \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wd9pkWL9ZWuO",
        "colab_type": "code",
        "outputId": "0608581e-1cc1-4848-dd8a-5f28890d5b4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def make_dirs(dirname):\n",
        "  if not os.path.exists(dirname):\n",
        "    os.makedirs(dirname)\n",
        "    \n",
        "    \n",
        "#make_dirs(\"logs\")\n",
        "%ls"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "homework_4.pdf  hw4_trs.pkl                   ngrok-stable-linux-amd64.zip.1\n",
            "hw4_te7.pkl     \u001b[0m\u001b[01;34mlogs\u001b[0m/                         ngrok-stable-linux-amd64.zip.2\n",
            "hw4_tes.pkl     \u001b[01;32mngrok\u001b[0m*                        ngrok-stable-linux-amd64.zip.3\n",
            "hw4_tr7.pkl     ngrok-stable-linux-amd64.zip  ngrok-stable-linux-amd64.zip.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R5QxokSPZP-B",
        "colab_type": "code",
        "outputId": "e6a9f077-d712-40ab-b2f7-753078fda994",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "## Logging\n",
        "LOG_DIR = 'logs/'\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "\n",
        "! wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "! unzip ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"\n",
        "    "
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-04 20:44:48--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.60.111, 52.4.95.48, 52.7.169.168, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.60.111|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14977695 (14M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.5’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  14.28M  13.4MB/s    in 1.1s    \n",
            "\n",
            "2019-04-04 20:44:49 (13.4 MB/s) - ‘ngrok-stable-linux-amd64.zip.5’ saved [14977695/14977695]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ngrok                   \n",
            "https://61e50d4c.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vykYuxEwaJaq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Running Average"
      ]
    },
    {
      "metadata": {
        "id": "AUkR914ZaCY1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RunningAverage ():\n",
        "    \"\"\"A simple class that maintains the running average of a quantity\n",
        "    Example:\n",
        "    ```\n",
        "    loss_avg = RunningAverage()\n",
        "    loss_avg.update(2)\n",
        "    loss_avg.update(4)\n",
        "    loss_avg() = 3\n",
        "    ```\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__( self ):\n",
        "        self.steps = 0\n",
        "        self.total = 0\n",
        "\n",
        "    def update( self, val ):\n",
        "        self.total += val\n",
        "        self.steps += 1\n",
        "\n",
        "    def __call__( self ):\n",
        "        return self.total / float ( self.steps )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Yc0VijLGaT5R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DataLoader"
      ]
    },
    {
      "metadata": {
        "id": "Bn5zA9K7aLSD",
        "colab_type": "code",
        "outputId": "19cf321f-1153-4939-9a07-e7da41b8dfdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def load_pickle(file):\n",
        "  with open(file, 'rb') as f:\n",
        "    data = pickle.load(f)\n",
        "  return data\n",
        "\n",
        "\n",
        "train = load_pickle(\"hw4_tr7.pkl\")\n",
        "test = load_pickle(\"hw4_te7.pkl\")\n",
        "\n",
        "print(f\"Train: {train.shape}, test:{test.shape}\")\n",
        "\n",
        "train = np.array(train)\n",
        "test = np.array(test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: (6265, 28, 28), test:(1028, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zUB_SoYAae-h",
        "colab_type": "code",
        "outputId": "5b73fb51-2707-47a1-eb01-f553864ee8b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        }
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(np.array(train[2]))\n",
        "plt.show()\n",
        "plt.imshow(np.array(train[10]))\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEpVJREFUeJzt3VtMk/cfx/FPKbB6oFDmFp2iTNkh\nBDwAJtNk6oVREhNDpt64GwNLtmg0c0aHU6MzI5nBY9TosmQYgy7Rv84ZL1zi8MLEdNMtnhCjW11Q\nMx0Oa9AqB8v/YhmRgfKltDwF36+r8fTH02/3mDdPKU/ram1tbRUA4LkSnB4AAPoCYgkABsQSAAyI\nJQAYEEsAMCCWAGBALAHAgFgCgEFipN+4Z88eXbt2TS6XSwsWLFBWVlY05wKAuBLRmeXly5d1+/Zt\nlZWV6aOPPlJFRUW05wKAuBJRLC9evKiJEydKkkaMGKGHDx8qFApFdTAAiCcRxTIYDMrr9bZ97fV6\nFQwGozYUAMSbqLzAw3txAOjvIoqlz+drdyZ57949+Xy+qA0FAPEmoliOGzdOfr9fkhQIBOTz+TRg\nwICoDgYA8cQV6ftZ7tu3TzU1NXK5XCopKVFmZmaURwOA+BFxLAHgRcIVPABgQCwBwIBYAoABsQQA\nA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwB\nwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBL\nADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBYAoABsQQAg8RIvqm6\nulqbN29WRkaGJGnkyJEqLi6O6mAAEE8iiqUkZWdna9myZdGcBQDiFk/DAcAg4jPLmzdvasOGDXrw\n4IHmzZunsWPHRnMuAIgrrtbW1tbuflN9fb2uXLmiSZMm6c6dO/r888+1fft2JSZG3F4AiGsRPQ1P\nT0/X5MmT5XK5NHToUKWlpam+vj7aswFA3IgolqdOndLRo0clScFgUPfv31d6enpUBwOAeBLR0/BH\njx5p27ZtCoVCamlp0dy5c5WXlxeL+QAgLkQUSwB40fCKTC94/Pixea3H4zGta2lpMe8zHA6b14ZC\noU63p6WlKRgMtvsaeJHwd5YAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYEAsAcCA\nyx17QXcud6yoqDCtCwQC5n0+fZliV8rLy6O+z+6ora01rYvVm003NTWZ1iUnJ8fk/hG/OLMEAANi\nCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKAAbEEAAM+3TFC27dv73T74sWLO9z2ySef9MZIUfGs\nDzd78uSJ3G5329cJCbH5OfvLL7+Y1q1fv968z2f9Ez906JDmzJnTbtu3335r2mddXZ35/ocPH25e\ni/jFmSUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADDgA8t6wbMuIexMLC4j\njNb9x+oSx6fl5+eb1nXnMT3PkSNH2n1dVFRk+r4//vjDfB/Z2dnmtf/73//Ma0tLSzts+/LLLzts\nt34InfTPZa3oHGeWAGBALAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsAMCCWAGBALAHAgE93jFBL\nS0un2xMTEzvcdv36dfN+33777R7N1dN9Xr16tdPtzc3NSkpKitZIPRaNSzjj7TFJPX9cPX1M3bn/\nkydPmtZNmTIl0nHiiuna8NraWpWXl2vWrFkqLCzU3bt3tWPHDoXDYaWlpWnx4sVx948OAKKpy6fh\njx8/VkVFhXJyctq2HThwQDNnztT69es1dOhQ808YAOiruoxlUlKSVq5cKZ/P17aturpaBQUFkqSC\nggJduHAhdhMCQBzo8mm42+2W2+1ut62xsbHtabfX61UwGIzNdAAQJ3g/ywglJj77f91/b3vjjTfM\n+43n9xNsbm52eoSo4zHBKqJYejweNTU1KTk5WfX19e2eor8oeDXcWbwazqvhvS2iv7PMzc2V3++X\nJPn9fo0fPz6qQwFAvOnyzDIQCGjv3r2qq6uT2+2W3+/XkiVLtHPnTp04cUJDhgzR1KlTe2NWAHBM\nl7EcPXq01q1b12H7mjVrYjEPAMQlXuCJUKxe4Lly5UrEMz1LWlqaee3zPjBs2LBhbf9969atHs30\nLL3xoWjR8PLLL5vXdud3docOHYpknKiZM2eOeW1/+V2kVd/4lwkADiOWAGBALAHAgFgCgAGxBAAD\nYgkABsQSAAyIJQAYEEsAMCCWAGDA5Y5xpjuXRsbCjz/+GNFt0fLmm2/26j6zsrLaff3bb7+Z9nnw\n4EHz/b/77rvmtf9+AoHF+fPnzWvRc5xZAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIBY\nAoABsQQAA1dra2ur00MA/7p69app3UsvvWTe56hRoyIdJypKS0vNazdt2tSj+2publZSUlLE3x8I\nBMxrMzIyIr6fvogzSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAw4AoeIAKhUMi8\nNiUlJYaTtPfkyRO53e522+rr683fn5qaGu2R+g3OLAHAgFgCgAGxBAADYgkABsQSAAyIJQAYEEsA\nMCCWAGBALAHAgFgCgEGi0wMAfdHatWtjst+EhJ6fv0RjH+iI/6sAYGA6s6ytrVV5eblmzZqlwsJC\n7dy5U4FAoO0NAmbPnq28vLyYDgoATuoylo8fP1ZFRYVycnLabZ8/f77y8/NjNhgAxJMun4YnJSVp\n5cqV8vl8vTEPAMQl8/tZHjhwQF6vt+1peDAYVEtLi1JTU1VcXCyv1xvrWQHAMRG9Gj5lyhSlpKQo\nMzNTR44c0cGDB1VSUhLt2YC4tXz5cvPazZs3m9f29JXs5uZmJSUltdt29+5d8/fz5r/PFtGRyc3N\nVWZmpiSpoKBAtbW10ZwJAOJORLHcuHGj7ty5I0mqrq5WRkZGVIcCgHjT5dPwQCCgvXv3qq6uTm63\nW36/X4WFhdq6dauSk5Pl8Xi0cOHC3pgVABzTZSxHjx6tdevWddj+zjvvxGIeAIhLXO6Ifu/69eud\nbn/99dc73Gb92+H79++b75/LD/sHjiIAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUA\nGBBLADDgckf0Sbdu3TKvbWpqMt/W0NAQ8UzR8MUXX5jXPus9NRsbG9t9zeWW0cH/RQAwIJYAYEAs\nAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwcLW2trY6PQT6twcPHkR9nxMnTjSvDQaDnW7/888/\nNWzYsHbb/vrrL9M+w+Gw+f6HDx9uXvvzzz+b17722mvmteg5ziwBwIBYAoABsQQAA2IJAAbEEgAM\niCUAGBBLADAglgBgQCwBwIBYAoABH1iGmGtpaTGvfeWVV2I4SUd3795t97XX6zV937lz58z3MWrU\nqG7NhPjEmSUAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADDgckfE3Keffur0\nCGYffPCBaR2XML54TLGsrKxUTU2NwuGwioqKNGbMGO3YsUPhcFhpaWlavHixkpKSYj0rADimy1he\nunRJN27cUFlZmRoaGrRixQrl5uZq5syZmjRpkvbv36+TJ09qxowZvTEvADiiy99ZZmdna+nSpZKk\nQYMGqbGxUdXV1SooKJAkFRQU6MKFC7GdEgAc1mUsExIS5PF4JElVVVWaMGGCGhsb2552e71eBYPB\n2E4JAA4zv8Bz5swZVVVVafXq1VqyZEksZ0I/89VXX8VkbTQ0Nzf36v2h7zLF8ty5czp8+LBWrVql\ngQMHyuPxqKmpScnJyaqvr5fP54v1nOjDPvzwQ/Pab775JoaTtNfc3NzhhcmPP/7Y9L3l5eWxGAlx\nrMun4aFQSJWVlSotLdXgwYMlSbm5ufL7/ZIkv9+v8ePHx3ZKAHBYl2eWp0+fVkNDg7Zs2dK2bdGi\nRdq9e7dOnDihIUOGaOrUqTEdEgCc1mUsp0+frunTp3fYvmbNmpgMBADxiCt40I7L5ep0e2tra7vb\n+tIVLHl5eebb1q9fH+tx0EdxbTgAGBBLADAglgBgQCwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBL\nADDgcscXwJ49e8xrExKe/fPz6dtu3LjRk5Ge6b333jOt6877Xqanpz/ztp9++sm8H7zYOLMEAANi\nCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGXO74Aqiuro76Pp93WWRPvPrqq6Z1\nz7uEEYgFziwBwIBYAoABsQQAA2IJAAbEEgAMiCUAGBBLADAglgBgQCwBwIArePqo5cuXm9du3rzZ\nvHbMmDGm28aPH2/eZ3ds2rQpJvsFeoozSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQ\nSwAwIJYAYMDljmgnMfHZ/ySevm3v3r3mfXo8nh7NBMQDUywrKytVU1OjcDisoqIinT17VoFAQCkp\nKZKk2bNnKy8vL6aDAoCTuozlpUuXdOPGDZWVlamhoUErVqxQTk6O5s+fr/z8/N6YEQAc12Uss7Oz\nlZWVJUkaNGiQGhsbFQ6HYz4YAMSTLmOZkJDQ9junqqoqTZgwQQkJCTp+/LiOHTum1NRUFRcXy+v1\nxnxYAHCKq7W1tdWy8MyZM/ruu++0evVq/f7770pJSVFmZqaOHDmiv//+WyUlJbGeFQAcY3qB59y5\nczp8+LBWrVqlgQMHKjc3t+22goICff311zEbEJ2L1Zv/vvXWW51uv3z5srKzs9u+/vXXX8375NVw\n9Add/p1lKBRSZWWlSktLNXjwYEnSxo0bdefOHUlSdXW1MjIyYjslADisyzPL06dPq6GhQVu2bGnb\nNm3aNG3dulXJycnyeDxauHBhTIcEAKd1Gcvp06dr+vTpHbZPmzYtFvMAQFzickcAMDC/Go4Xw9Mv\n4jztvy/wXL58ubdGAuICZ5YAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYMAVPABg\nwJklABgQSwAwIJYAYEAsAcCAWAKAAbEEAANiCQAGxBIADIglABgQSwAwIJYAYEAsAcCAWAKAAbEE\nAANiCQAGxBIADIglABgkOnGne/bs0bVr1+RyubRgwQJlZWU5MUZUVVdXa/PmzcrIyJAkjRw5UsXF\nxQ5PFbna2lqVl5dr1qxZKiws1N27d7Vjxw6Fw2GlpaVp8eLFSkpKcnrMbvnvY9q5c6cCgYBSUlIk\nSbNnz1ZeXp7DU3ZPZWWlampqFA6HVVRUpDFjxvT54yR1fFxnz551/Fj1eiwvX76s27dvq6ysTDdv\n3tSuXbtUVlbW22PERHZ2tpYtW+b0GD32+PFjVVRUKCcnp23bgQMHNHPmTE2aNEn79+/XyZMnNWPG\nDAen7J7OHpMkzZ8/X/n5+Q5N1TOXLl3SjRs3VFZWpoaGBq1YsUK5ubl9+jhJnT+unJwcx49Vrz8N\nv3jxoiZOnChJGjFihB4+fKhQKNTbY+A5kpKStHLlSvl8vrZt1dXVKigokCQVFBTowoULTo0Xkc4e\nU1+XnZ2tpUuXSpIGDRqkxsbGPn+cpM4fVzgcdngqB84sg8GgRo8e3fa11+tVMBjUwIEDe3uUqLt5\n86Y2bNigBw8eaN68eRo7dqzTI0XE7XbL7Xa329bY2Nj2dO7fY9aXdPaYJOn48eM6duyYUlNTVVxc\nLK/X68B0kUlISJDH45EkVVVVacKECTp//nyfPk5S548rISHB8WPl+As8/eXDJYcNG6Z58+ZpxYoV\nWrRokXbt2qWWlhanx8JzTJkyRe+//77Wrl2rzMxMHTx40OmRInLmzBlVVVWppKTE6VGi6unHFQ/H\nqtdj6fP52v20u3fvXr94apSenq7JkyfL5XJp6NChSktLU319vdNjRY3H41FTU5Mkqb6+vl8cs9zc\nXGVmZkr65ylrbW2tswNF4Ny5czp8+LA+++wzDRw4sN8cp/8+rng4Vr0ey3Hjxsnv90uSAoGAfD6f\nBgwY0NtjRN2pU6d09OhRSf/8quH+/ftKT093eKroyc3NbTtufr9f48ePd3iintu4caPu3Lkj6Z/f\nyf77lwx9RSgUUmVlpUpLSzV48GBJ/eM4dfa44uFYuVodeB68b98+1dTUyOVyqaSkpO0nRl/26NEj\nbdu2TaFQSC0tLZo7d26f+zOUfwUCAe3du1d1dXVyu91KT0/XkiVLtHPnTjU3N2vIkCFauHChEhMd\n+cuziHT2mAoLC/X9998rOTlZHo9HCxcuVGpqqtOjmp04cUIHDx7UsGHD2rYtWrRIu3fv7rPHSer8\ncU2bNk0//PCDo8fKkVgCQF/j+As8ANAXEEsAMCCWAGBALAHAgFgCgAGxBAADYgkABsQSAAz+D/i/\n8QUZKrBDAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "4_gWBXB7bE6G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 25\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, num_workers=2, batch_size=batch_size,\n",
        "\t\t\t\t\t\t\t\tshuffle=True, drop_last=True, pin_memory=True)\n",
        "test_loader = torch.utils.data.DataLoader(test, num_workers=2, batch_size=batch_size,\n",
        "\t\t\t\t\t\t\t\tshuffle=True, drop_last=True, pin_memory=True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KySFfsO-c_Bl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2Q1FPJEkgV9E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network"
      ]
    },
    {
      "metadata": {
        "id": "Vc-95FWSdDqg",
        "colab_type": "code",
        "outputId": "88104a20-ba36-4bd8-bab6-ea3d5b54819b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(f\"Total number of train images: {train.shape[0]}, total number of test images: {test.shape[0]}, total number of train batches: {len(train_loader)}\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of train images: 6265, total number of test images: 1028, total number of train batches: 250\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nJtLW142dFhU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Flatten(nn.Module):\n",
        "    def forward(self, input):\n",
        "        return input.view(input.size(0), -1)\n",
        "\n",
        "\n",
        "class UnFlatten(nn.Module):\n",
        "    def forward(self, input, size=1024):\n",
        "        return input.view(input.size(0), size, 1, 1)\n",
        "\n",
        "      \n",
        "class ConvVAE(nn.Module):\n",
        "    def __init__(self, nb_latents):\n",
        "        super(ConvVAE, self).__init__()\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        \n",
        "        self.conv3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        \n",
        "        self.conv4 = nn.Sequential(\n",
        "            nn.Conv2d(128, 256, kernel_size=2, stride=1),\n",
        "            nn.ReLU())\n",
        "        \n",
        "        self.fc1 = nn.Linear(1024, 256)\n",
        "        \n",
        "        self.fc_mean = nn.Linear(256, nb_latents)\n",
        "        self.fc_std = nn.Linear(256, nb_latents)\n",
        "        \n",
        "        self.fc2 = nn.Linear(nb_latents, 256)\n",
        "        self.fc3 = nn.Linear(256, 1024)\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.fc4 = nn.Linear(1024,7*7*64)\n",
        "        \n",
        "        self.deconv1 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(32, 1, kernel_size=2, stride=2)\n",
        "    \n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "    def encode(self, x):\n",
        "        x = (self.conv1(x))\n",
        "        \n",
        "        x =  (self.conv2(x))\n",
        "         \n",
        "        x =  (self.conv3(x))\n",
        "         \n",
        "        x =  (self.conv4(x))\n",
        "        \n",
        "        x = x.reshape(x.size(0), -1)\n",
        "        \n",
        "        x = self.relu(self.fc1(x))\n",
        "        return self.fc_mean(x), self.fc_std(x)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        if self.training:\n",
        "            std = logvar.mul(0.5).exp_()\n",
        "            eps = Variable(std.data.new(std.size()).normal_())\n",
        "            return eps.mul(std).add_(mu)\n",
        "        else:\n",
        "            return mu\n",
        "    \n",
        "    def decode(self, z):\n",
        "        x = self.relu(self.fc2(z))\n",
        "         \n",
        "        x = self.relu(self.fc3(x))\n",
        "        \n",
        "        x = self.relu(self.fc4(x))\n",
        "         \n",
        "        x = self.relu(self.deconv1(x.view(-1, 64, 7, 7)))\n",
        "        x = self.deconv2(x)\n",
        "         \n",
        "        return self.sigmoid(x)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.unsqueeze(1))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hyaFu-GkgYAL",
        "colab_type": "code",
        "outputId": "b98440ee-02be-48df-e72c-0c1b1b5af148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "cell_type": "code",
      "source": [
        "model = ConvVAE(3)\n",
        "if is_cuda:\n",
        "  model = model.to(device)\n",
        "  \n",
        "print(model)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ConvVAE(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv3): Sequential(\n",
            "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv4): Sequential(\n",
            "    (0): Conv2d(128, 256, kernel_size=(2, 2), stride=(1, 1))\n",
            "    (1): ReLU()\n",
            "  )\n",
            "  (fc1): Linear(in_features=1024, out_features=256, bias=True)\n",
            "  (fc_mean): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (fc_std): Linear(in_features=256, out_features=3, bias=True)\n",
            "  (fc2): Linear(in_features=3, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=3136, bias=True)\n",
            "  (deconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (deconv2): ConvTranspose2d(32, 1, kernel_size=(2, 2), stride=(2, 2))\n",
            "  (relu): ReLU()\n",
            "  (sigmoid): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V_Ni_rVyjMGf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loss Function - KL divergence and Reconstruction Loss"
      ]
    },
    {
      "metadata": {
        "id": "gAP2JoG1g0MW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "### Loss Function\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "  BCE = F.binary_cross_entropy(recon_x,x.view(-1,784),reduction=\"sum\")\n",
        "  # https://arxiv.org/abs/1312.6114\n",
        "  # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "  KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "  \n",
        "  return BCE + KLD\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aaCjMSQ2mAVm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##Params"
      ]
    },
    {
      "metadata": {
        "id": "ijsLxN3GhDT5",
        "colab_type": "code",
        "outputId": "97e4c6b7-34dc-4b8d-beff-a2fcbec8f111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"batch_size\":25,\n",
        "    \"epochs\" : 10,\n",
        "    \"log_interval\":10,\n",
        "    \"nb_latents\" : 3,\n",
        "    \"save_interval\":10,\n",
        "    \n",
        "}\n",
        "\n",
        "torch.manual_seed(5)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1a46f354b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "metadata": {
        "id": "Ghp-4XYsjcrJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train Network"
      ]
    },
    {
      "metadata": {
        "id": "Rh3bh8G7jdy3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "logger = TensorBoardLogger(\"./logs\") \n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "\"\"\"\n",
        "Traverse Latents\n",
        "\"\"\"\n",
        "def traverse_latents(model, datapoint, nb_latents, epoch, batch_idx, dirpath=\"logs\",istrain=True):\n",
        "  model.eval()\n",
        "  \n",
        "  if isinstance(model,ConvVAE):\n",
        "    datapoint = datapoint.unsqueeze(0)\n",
        "    datapoint = datapoint.unsqueeze(0).to(device)\n",
        "    mu, _ = model.encode(datapoint)\n",
        "  else:\n",
        "    mu, _ = model.encode(datapoint.view(-1))\n",
        "  \n",
        "  recons = torch.zeros((7, nb_latents, 28, 28))\n",
        "  \n",
        "  for zi in range(nb_latents):\n",
        "    muc = mu.squeeze().clone()\n",
        "    \n",
        "    for i, val in enumerate(np.linspace(-3, 3, 7)):\n",
        "      muc[zi] = val\n",
        "       \n",
        "      recon = model.decode(muc).cpu()\n",
        "      recons[i, zi] = recon.view(28, 28)\n",
        "  \n",
        "  name = \"train_reconstruction_\" if istrain else \"test_reconstruction_\"\n",
        "  filename = os.path.join(dirpath,  name + str(epoch) + '_' + str(batch_idx) + '.png')\n",
        "  save_image(recons.view(-1, 1, 28, 28), filename, nrow=nb_latents, pad_value=1)\n",
        "  \n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  \n",
        "  \n",
        "  loss_log = RunningAverage()\n",
        "  \n",
        "  ## Test reconstruction test\n",
        "  testpoint = torch.Tensor(train_loader.dataset[0])\n",
        "  \n",
        "  for batch_idx, (data ) in enumerate(train_loader):\n",
        "    data = data.to(device)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    batch_size = data.size(0)\n",
        "    \n",
        "    recon_batch, mu, logvar = model(data)\n",
        "    \n",
        "    \n",
        "    ## Loss of VAE\n",
        "    loss = loss_function(recon_batch.squeeze().view(-1,28*28), data, mu, logvar)\n",
        "    loss.backward()\n",
        "    \n",
        "    loss_log.update(loss.item() / len(data))\n",
        "    \n",
        "    # 1. Log scalar values (scalar summary)\n",
        "    info = { 'loss': loss }\n",
        "\n",
        "    for tag, value in info.items():\n",
        "      logger.scalar_summary(tag, value, epoch+1)\n",
        "\n",
        "    # 2. Log values and gradients of the parameters (histogram summary)\n",
        "    for tag, value in model.named_parameters():\n",
        "      tag = tag.replace('.', '/')\n",
        "      logger.histo_summary(tag, value.data.cpu().numpy(), epoch+1)\n",
        "      logger.histo_summary(tag+'/grad', value.grad.data.cpu().numpy(), epoch+1)\n",
        "\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    ## Accuracy \n",
        "    if batch_idx % params.get(\"log_interval\") == 0:\n",
        "      \n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}, \\t '.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "      \n",
        "    if not batch_idx % params.get(\"save_interval\"):\n",
        "      traverse_latents(model, testpoint, params.get(\"nb_latents\"), epoch, batch_idx)\n",
        "    \n",
        "      \n",
        "  print(\"==> Epoch {}, average loss: {:.4f}\".format(epoch, loss_log()))\n",
        "  return loss_log()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "han-3Vsqnusx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Test"
      ]
    },
    {
      "metadata": {
        "id": "BjF1pTT2nwRj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Test\n",
        "\"\"\"\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = RunningAverage()\n",
        "    \n",
        "    ## Test reconstruction test\n",
        "    testpoint = torch.Tensor(test_loader.dataset[0])\n",
        "  \n",
        "    with torch.no_grad():\n",
        "        for i, (data) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "             \n",
        "            batch_size = data.size(0)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            ## Loss of VAE\n",
        "            loss = loss_function(recon_batch.squeeze().view(-1,28*28), data, mu, logvar)\n",
        "            test_loss.update(loss.item() / len(data))\n",
        "            # 1. Log scalar values (scalar summary)\n",
        "            info = { 'test_loss': loss }\n",
        "\n",
        "            for tag, value in info.items():\n",
        "                logger.scalar_summary(tag, value, epoch+1)\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                p = recon_batch.squeeze().view(-1,28,28)[:n]\n",
        "                comparison = torch.cat([data[:n].view(-1,28,28),p])\n",
        "               \n",
        "                traverse_latents(model, comparison[0], params.get(\"nb_latents\"), epoch, i, istrain=False)\n",
        "\n",
        "   \n",
        "    return test_loss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-ekoQ2E4mPAH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loss = []\n",
        "test_loss = []\n",
        "\n",
        "for epoch in range(1, params.get(\"epochs\") + 1):\n",
        "        trainloss = train(epoch)\n",
        "        train_loss.append(trainloss)\n",
        "        \n",
        "        \n",
        "        ## test \n",
        "        tes_loss = test(epoch)\n",
        "        test_loss.append(tes_loss)\n",
        "        \n",
        "        \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qvwDEDwWonHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "27853ca4-7605-4c6f-f037-809d9b070120"
      },
      "cell_type": "code",
      "source": [
        "testpoint = torch.Tensor(test_loader.dataset[0])\n",
        "testpoint.size()"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([28, 28])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 193
        }
      ]
    },
    {
      "metadata": {
        "id": "ZUZmshiBuT1h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}